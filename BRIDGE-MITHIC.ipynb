{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bff33e5b",
   "metadata": {},
   "source": [
    "## Resource "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169d7573",
   "metadata": {},
   "source": [
    "**Paper BRIDGE**: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text (https://arxiv.org/abs/2504.19467)\n",
    "\n",
    "**Github repo**: BRIDGE (https://github.com/YLab-Open/BRIDGE)\n",
    "\n",
    "**Dataset**: BRIDGE-Open (https://huggingface.co/datasets/YLab-Open/BRIDGE-Open)\n",
    "\n",
    "**Leaderboards**: BRIDGE-Medical-Leaderboard (https://huggingface.co/spaces/YLab-Open/BRIDGE-Medical-Leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0a5de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55405afe",
   "metadata": {},
   "source": [
    "## Download and organize files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a919ca4f",
   "metadata": {},
   "source": [
    "(Optional) A. Download the dataset from Hugging Face via python script\n",
    "\n",
    "See dataset_download.py for more details.\n",
    "\n",
    "(Requirement: pip install huggingface_hub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc97867",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396a082",
   "metadata": {},
   "source": [
    "(Optional) B. Manually Download the dataset from Hugging Face\n",
    "\n",
    "1. Web: https://huggingface.co/datasets/YLab-Open/BRIDGE-Open/tree/main\n",
    "\n",
    "2. Manually download **\"Dataset.zip\"** and **\"Examples.zip\"** files\n",
    "\n",
    "3. Extract them to the **\"dataset_raw\"** directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e4dcc",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d54fce",
   "metadata": {},
   "source": [
    "Finally, the directory structure should look like this:\n",
    "```\n",
    "dataset_raw/\n",
    "├── task_1.SFT.json\n",
    "├── task_1.SFT.json\n",
    "└── example/\n",
    "    ├── task_1.example.json\n",
    "    ├── task_1.example.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e86c6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d68e264d",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ad743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Any\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292b279b",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f6f8b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tasks(root: str | Path = \"dataset_raw\") -> dict[str, dict[str, Any]]:\n",
    "    root = Path(root)\n",
    "    \n",
    "    def read_json(path: Path) -> Any:\n",
    "        with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    data_files    = {p.name.split(\".SFT\", 1)[0]: p for p in root.glob(\"*.SFT.json\")}\n",
    "    example_files = {p.name.split(\".example\", 1)[0]: p for p in (root / \"example\").glob(\"*.example.json\")}\n",
    "\n",
    "    assert set(data_files.keys()) == set(example_files.keys()), \\\n",
    "        \"Data and example files must match in task names.\"\n",
    "\n",
    "    dict_task_data: dict[str, dict[str, Any]] = {}\n",
    "\n",
    "    for task in data_files:\n",
    "        dict_task_data[task] = {\n",
    "            \"example\": read_json(example_files[task]),\n",
    "            \"test\":    read_json(data_files[task]),\n",
    "        }\n",
    "        dict_task_data[task][\"corpus\"] = [ data['input'] for data in dict_task_data[task][\"example\"] ] + [ data['input'] for data in dict_task_data[task][\"test\"] ]\n",
    "\n",
    "    return dict_task_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edae7146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all tasks from the dataset folder\n",
    "path_dir_data = \"dataset_raw\"\n",
    "dict_task_data = load_tasks(root=path_dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c993a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d82ecb5a",
   "metadata": {},
   "source": [
    "## Explore data for a specific task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412f49d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: BrainMRI-AIS\n",
      "Number of 'examples': 5\n",
      "Number of 'test' cases: 267\n",
      "Number of 'corpus' entries: 272\n"
     ]
    }
   ],
   "source": [
    "# Example usage: get one specific task\n",
    "task_name = \"BrainMRI-AIS\"\n",
    "task_data = dict_task_data[task_name]\n",
    "print(f\"Task: {task_name}\")\n",
    "print(f\"Number of 'examples': {len(task_data['example'])}\")\n",
    "print(f\"Number of 'test' cases: {len(task_data['test'])}\")\n",
    "print(f\"Number of 'corpus' entries: {len(task_data['corpus'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d66b5373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus:\n",
      "Unremarkable finding of brain parenchyma and cerebrospinal fluid space.\n",
      "magnetic resonance angiography: No gross abnormal finding.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Review the corpus\n",
    "idx = 1\n",
    "example_one = task_data[\"corpus\"][idx]\n",
    "print(f\"Corpus:\\n{example_one}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8de1d44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: BrainMRI-AIS\n",
      "\n",
      "language: en\n",
      "\n",
      "task type: Text Classification\n",
      "\n",
      "id: 1\n",
      "\n",
      "split: test\n",
      "\n",
      "instruction: Given a brain Magnetic Resonance Imaging (MRI) radiology report, determine whether the patient has acute ischemic stroke (AIS).\n",
      "Return your answer in the following format. DO NOT GIVE ANY EXPLANATION:\n",
      "AIS: label\n",
      "The optional list for \"label\" is [\"Yes\", \"No\"].\n",
      "\n",
      "input: Multiple unidentified bright objects or small vessel diseases in both cerebral subcortical white matter\n",
      "No diffusion restriction\n",
      "magnetic resonance angiography: No gross abnormal finding.\n",
      "\n",
      "pred: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A whole data from test\n",
    "idx = 1\n",
    "test_one = task_data[\"test\"][idx]\n",
    "for key, value in test_one.items():\n",
    "    print(f\"{key}: {value.strip() if isinstance(value, str) else value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965ab3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: BrainMRI-AIS\n",
      "\n",
      "language: en\n",
      "\n",
      "task type: Text Classification\n",
      "\n",
      "id: 1661\n",
      "\n",
      "split: train\n",
      "\n",
      "instruction: Given a brain Magnetic Resonance Imaging (MRI) radiology report, determine whether the patient has acute ischemic stroke (AIS).\n",
      "Return your answer in the following format. DO NOT GIVE ANY EXPLANATION:\n",
      "AIS: label\n",
      "The optional list for \"label\" is [\"Yes\", \"No\"].\n",
      "\n",
      "input: Unremarkable finding of brain parenchyma and cerebrospinal fluid space.\n",
      "magnetic resonance angiography: No gross abnormal finding.\n",
      "\n",
      "output: AIS: No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A whole data from example\n",
    "idx = 1\n",
    "example_one = task_data[\"example\"][idx]\n",
    "for key, value in example_one.items():\n",
    "    print(f\"{key}: {value.strip() if isinstance(value, str) else value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d443ac5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57507ddd",
   "metadata": {},
   "source": [
    "## Research Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f9f642",
   "metadata": {},
   "source": [
    "- Is there a topic correlation between clinical notes vs medical exam questions?\n",
    "\n",
    "- Are patients of different genders, races, or socioeconomic backgrounds documented differently in clinical notes?\n",
    "\n",
    "- How do discharge summary contents vary across countries with different health systems (e.g., single-payer vs. privatized)?\n",
    "\n",
    "- Do clinicians in different countries document differently when it comes to family involvement, religious beliefs, end-of-life care, or alternative medicine?\n",
    "\n",
    "- How have certain conditions (e.g., HIV, COVID-19, opioid use disorder) been described and framed over time in discharge summaries?\n",
    "\n",
    "- Are there notable differences in how the same clinical concept is expressed across languages (e.g., pain)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70af7608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab41300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218090ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
